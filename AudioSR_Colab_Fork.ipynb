{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sweye/audiosr_fixed/blob/main/AudioSR_Colab_Fork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYuiV2rlDizI"
      },
      "source": [
        "# AudioSR-Colab-Fork v0.5\n",
        "\n",
        "---\n",
        "Colab adaptation of AudioSR, with some tweaks:\n",
        "\n",
        "v0.5\n",
        "- input audio is resampled accordingly to 'input_cutoff' (instead of lowpass filtering)\n",
        "- each processed chunk is normalised at same LUFS level than input chunk (fix the volume drop issue)\n",
        "\n",
        "v0.4\n",
        "- code rework, inference.py created for local CLI usage.\n",
        "\n",
        "v0.3\n",
        "- added : multiband ensemble option to use original audio below the given cutoff frequency and the generated audio above.\n",
        "- fixed : other than .wav input error while saving the final audio\n",
        "\n",
        "v0.2\n",
        "- added a chunking feature to process input of any length\n",
        "- added stereo handling, stereo input channels will be splitted and processed independantly (dual mono) and then reconstructed as stereo audio.\n",
        "- added overlap feature to smooth the transitions between chunks (don't use high values because AudioSR is not 100% phase accurate and this will create weird phase cancellations accross the overlapping regions)\n",
        "---\n",
        "Adaptation & tweaks by [jarredou](https://https://github.com/jarredou/)\n",
        "\n",
        "Original work [AudioSR: Versatile Audio Super-resolution at Scale](https://github.com/haoheliu/versatile_audio_super_resolution) by Haohe Liu, Ke Chen, Qiao Tian, Wenwu Wang, Mark D. Plumbley\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7t23Tz5XIcON"
      },
      "outputs": [],
      "source": [
        "#@markdown # Installation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/haoheliu/versatile_audio_super_resolution.git\n",
        "%cd versatile_audio_super_resolution\n",
        "!pip install cog huggingface_hub unidecode phonemizer einops torchlibrosa transformers ftfy timm librosa pyloudnorm\n",
        "!pip install huggingface_hub transformers==4.30.2 gradio soundfile progressbar librosa audiosr unidecode\n",
        "#!pip install -r requirements.txt\n",
        "\n",
        "!wget https://raw.githubusercontent.com/jarredou/AudioSR-Colab-Fork/main/inference.py\n",
        "#from IPython.display import clear_output\n",
        "#clear_output(wait=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWUd27QECiLw"
      },
      "source": [
        "### **IMPORTANT NOTE**\n",
        "\n",
        "#### If the inference cell crashes, restart the runtime (do not disconnect, just restart it), else it will cause memory errors !\n",
        "\n",
        "*If you're are doing multiple runs, think also to restart the runtime every 4 or 5 files to clean up memory*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WfjZ_Q0OIepR"
      },
      "outputs": [],
      "source": [
        "%cd /content/versatile_audio_super_resolution\n",
        "import gc\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from scipy.signal.windows import hann\n",
        "import soundfile as sf\n",
        "import torch\n",
        "from cog import BasePredictor, Input, Path\n",
        "import tempfile\n",
        "import librosa\n",
        "from audiosr import build_model, super_resolution\n",
        "from scipy import signal\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "\n",
        "#@markdown #Inference\n",
        "input_file_path = '/content/drive/MyDrive/input' #@param {type:\"string\"}\n",
        "output_folder = '/content/drive/MyDrive/output_folder' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "ddim_steps= 20 #@param {type:\"slider\", min:20, max:200, step:10}\n",
        "overlap = 0.04 #@param {type:\"slider\", min:0, max:0.96, step:0.04}\n",
        "guidance_scale=3.5 #@param {type:\"slider\", min:1, max:15, step:0.5}\n",
        "seed = 0 # @param {type:\"integer\"}\n",
        "chunk_size = 10.24 # @param [5.12, 10.24, 20.48] {type:\"raw\"}\n",
        "multiband_ensemble = True # @param {type:\"boolean\"}\n",
        "input_cutoff = \"14000\" #@param [20000, 19000, 18000, 17000, 16000, 14000, 13000, 12000, 11000, 10000, 9000, 8000, 7000, 6000, 5000, 4000, 3000, 2000]\n",
        "input_cutoff = int(input_cutoff)\n",
        "\n",
        "\n",
        "\n",
        "!python inference.py --input \"{input_file_path}\" \\\n",
        "                     --output \"{output_folder}\" \\\n",
        "                     --ddim_steps {ddim_steps} \\\n",
        "                     --guidance_scale {guidance_scale} \\\n",
        "                     --seed {seed} \\\n",
        "                     --chunk_size {chunk_size} \\\n",
        "                     --overlap {overlap} \\\n",
        "                     --multiband_ensemble {multiband_ensemble} \\\n",
        "                     --input_cutoff {input_cutoff}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}